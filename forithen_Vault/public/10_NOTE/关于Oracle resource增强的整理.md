## 背景

当前系统在生产环境中出现数据库性能瓶颈，主要表现为高负载时数据库响应时间上升，部分处理存在等待现象。经过初步分析，系统整体性能瓶颈集中在数据库层。

在数据库性能优化的一般原则中，通常应优先从业务端入手，对高负荷的SQL（Top SQL）进行调优，例如：

- 优化执行计划
    
- 调整索引结构
    
- 改善SQL逻辑
    

但在本项目中，由于业务侧的现实限制，现有SQL及处理逻辑难以进行修改。因此，本次性能改善的讨论方向主要集中在**数据库基础资源侧（基盘侧）的增强**。

在与基盘团队讨论后，虽然提出了应优先优化Top SQL的建议，但在业务侧坚持不变更SQL逻辑的前提下，最终整理出以下两个提案。

---

## 提案一：RDS实例类型变更（同规格升级）

根据AWS的许可证规则，在使用Oracle License Included模式时，4xlarge为无需BYOL（Bring Your Own License）的上限规格。

若继续通过增加CPU核心数或内存容量来提升性能，则需要切换至BYOL模式，会带来额外的许可证成本及运维复杂度。因此，本次未采用“横向增加资源量”的方案。

替代方案为：

将现有实例：

`db.r5.4xlarge`

升级为：

`db.r6i.4xlarge`

该方案属于：

- CPU架构升级
    
- 同规格资源量
    
- 不增加license成本
    
- 作业风险较低
    

根据Oracle及AWS官方资料，新一代实例在CPU性能及内存带宽方面均有提升，在不改变系统结构的前提下，预期可获得一定程度的性能改善。

该方案属于**短期、低风险的性能改善措施**。

---

## 提案二：数据库负载分散（单库向多库结构演进）

第二个方案为从架构层面分散数据库负载。

当前系统采用单一数据库结构，所有用户请求集中于同一个RDS实例，导致高并发时负载集中。

提案内容为：

- 将现有单一数据库拆分为两个数据库
    
- 将用户数据按一定规则分散到不同的RDS实例中
    
- 降低单个数据库的请求压力
    

该方案的特点：

- 可显著降低单库负载
    
- 有利于后续横向扩展
    
- 与未来多数据库架构演进方向一致
    

因此，该方案属于**中长期的结构性性能改善措施**，具备一定的扩展性和架构演进价值。
其实在提案2 中也可以分别对各个RDS追加实行提案1.


---


## 应用框架变更与数据库实例变更的关系

当前系统正在进行应用框架的更新，由原有的 **Seasar2 框架**，迁移至 **JavaEE + MyBatis** 的后端架构。  
由于该框架变更涉及系统核心处理逻辑，因此必须在上线前进行一次全面的性能测试，以确认新架构在性能和稳定性方面不会产生负面影响。

在本项目中：

- 应用框架变更统称为：**FW更改**
    
- Oracle RDS实例规格变更统称为：**instance type变更**
    

其中，本次数据库性能改善方案暂定采用提案一，即：

`db.r5.4xlarge → db.r6i.4xlarge`

---

## 时间线上的关键约束

本项目中，FW更改与instance type变更存在时间上的重叠关系，主要有以下两个关键节点：

### ① FW更改上线时间

- 预计上线时间：**7月**
    
- 因此在7月之前，本番环境仍运行**旧应用架构**
    

---

### ② instance type变更的契约时点

- AWS契约更新需在每年**4月**执行
    
- 因此是否将本番实例由R5变更为R6i，需在4月前做出决策
    

若决定实施instance type变更，则本番环境在**4月～7月期间**将处于以下组合：

`R6i实例 + 旧应用架构`

---

## 性能验证上的核心问题

原本的性能验证思路为：

`R6i实例 + 新应用架构 ↓ 进行性能测试 ↓ 确认性能改善及无负面影响`

但由于时间线的限制：

- 4月～7月期间，本番环境仍为旧应用
    
- 即存在一个未验证的组合：
    

`R6i实例 + 旧应用架构`

该组合在正式切换前，其性能影响尚未被确认。

因此追加了一项验证措施：

> 在regression环境中，将RDS实例变更为R6i，并使用旧应用进行小规模打键测试，以确认4月～7月期间本番环境的稳定性。

---

## regression环境性能测试的实施

该计划于去年10月确定，并在今年年初开始在regression环境实施性能测试。

本次性能测试分为两部分：

1. 单体性能测试
    
2. 综合性能测试
    

---

## 出现的问题与课题整理

### 课题1：单体性能测试环境规格不一致

在单体性能测试中，由于成本及历史原因，regression环境未使用与本番一致的实例规格。

实际测试环境：

`db.m5.xlarge`

而目标规格为：

`db.r5.4xlarge（现行本番） db.r6i.4xlarge（变更目标）`

当时的判断是：

- 单体测试负荷较小
    
- m5.xlarge足以承载
    
- 测试结果仍具有参考价值
    

但实际测试结果显示：

- 性能指标未达到目标
    
- 环境规格差异对测试结果产生影响
    

因此形成**性能课题1**。

---

### 课题2：综合性能测试中R6i表现异常

在对应单体性能课题的同时，进行了综合性能测试的实验打键。

本次测试中：

`regression环境实例： db.r6i.4xlarge`

但出现了明显异常：

> db.r6i.4xlarge 的性能反而不如 db.m5.xlarge

在资源规格明显更高的情况下出现性能劣化，判断为存在系统性问题。

---

## 当时的调查方向与结果

### 调查方向1：EBS性能问题

观察到：

- write latency上升
    
- TM lock等待
    

因此怀疑：

- EBS配置不合理
    
- 存储性能成为瓶颈
    

当前配置：

`gp2`

且资源量与本番一致。

AWS建议：

- 切换至gp3或更高等级存储
    

但由于经费限制：

- gp3方案虽成本增加较小
    
- 但验证暂时搁置
    

---

### 调查方向2：TM lock竞争

关于TM lock问题的技术判断为：

- R6i CPU性能更高
    
- 单位时间内处理SQL数量增加
    
- 对同一表的并发操作增加
    
- 导致锁竞争显性化
    

因此判断：

> 并非R6i引入新问题，而是更高性能暴露了原有SQL并发设计问题。

该问题本质上属于：

`SQL或业务逻辑层面的并发控制问题`

---

### 调查方向3：AZ跨区通信导致延迟

最终确认的核心问题为：

> 应用与数据库位于不同AZ，导致跨AZ通信延迟

在手动对齐应用与数据库的AZ之后：

`R6i性能恢复至预期水平`

同时确认：

- 本番环境在发生AZ切换时
    
- 同样会出现延迟现象
    

但由于系统当前无法实现跨AZ架构优化：

- 该问题暂不作为本次对应对象
    

---

## 当前的关键决策点

经过上述测试与调查，目前项目的核心问题变为：

> 是否在4月契约更新时，将本番环境实例由R5变更为R6i。

上述内容的
[[事后评价]]

# 以下是关于4月要不要换r6i到本番的检讨
## 综合判断

在以下现实条件下：

- 综合性能测试进度不明
    
- 无额外经费进行完整验证
    
- instance变更为同规格代际升级
    
- regression环境已确认系统可运行
    
- 基盘侧判断技术风险较低
    
- 契约窗口一年一次
    

因此决定：

> 通过选取部分单体测试用例，在R6i环境下进行一次最小规模的事前验证，作为4月是否实施instance变更的判断依据。

若该验证中未出现明显性能劣化或系统性问题，则认为：

`4月实施R6i instance变更具备可行性`
在决定以**单体性能测试作为4月是否更换R6i实例的判断依据**后，对instance type变更本身的风险进行了进一步技术层面的整理与讨论。

本阶段的讨论重点不再局限于此前测试中出现的个别现象，而是从**一般性的RDS实例代际变更风险**出发，对需要确认的技术要点进行了重新整理。

---

## instance type变更的一般性风险结构

在RDS中进行：

`db.r5.4xlarge → db.r6i.4xlarge`

这一类**同规格代际升级**时，理论上属于低风险操作，但仍存在以下三类需要确认的风险层级。

---

### ① 数据库内部资源模型变化

虽然实例规格保持为4xlarge，但由于底层硬件架构不同，可能导致：

- CPU性能特性变化
    
- 内存带宽变化
    
- Oracle内部内存结构重新分配
    

在RDS中，数据库的：

- 内存分配
    
- 并发能力
    
- 执行行为
    

主要由以下两部分共同决定：

`instance规格 + parameter group`

因此在instance变更时，可能出现以下情况：

- 总内存增加
    
- 但某些内部结构（如buffer cache）反而减少
    
- 导致部分SQL性能发生变化
    

该类问题属于：

> 数据库内部结构性变化

其特点为：

- 不依赖高并发
    
- 单体性能测试即可观测到
    

因此在本次单体测试中，将以下内容作为确认对象：

- 执行计划是否发生变化
    
- Top SQL耗时是否发生明显波动
    
- CPU/IO瓶颈类型是否发生变化
    
- 内存结构是否存在异常变化
    

---

### ② 高并发下的锁竞争风险

在此前的regression综合性能测试中，曾观测到：

`TM lock等待`

经过讨论确认：

- TM lock属于表级锁竞争
    
- 本质上是高并发下的业务锁冲突问题
    

其形成机制为：

`CPU性能提升 → SQL执行节奏加快 → 并发冲突更集中 → 锁竞争显性化`

因此：

> R6i并不会引入新的锁问题，而是更容易暴露原有的并发设计瓶颈。

该类问题的特点为：

- 仅在高并发下出现
    
- 单体测试无法完全复现
    
- 需要综合性能测试或本番负荷才能确认
    

因此在单体测试阶段：

- 不以“锁竞争”为主要判断依据
    
- 仅确认无结构性性能劣化
    

---

### ③ AZ与网络路径差异带来的性能波动

在此前的regression综合测试中确认：

- 应用与DB跨AZ部署时
    
- 会产生明显处理时间差异
    

该现象在本番环境中亦被观测到。

AWS侧反馈为：

> AZ构成差异导致的响应差异属于正常现象。

其技术本质为：

`系统SQL往返频繁 → 对网络延迟敏感 → 跨AZ时延迟放大 → 整体处理时间增加`

该问题属于：

- 架构层面的性能特性
    
- 与instance类型无直接因果关系
    

因此在本次instance变更判断中：

- 不将AZ差异作为否决要因
    
- 仅记录为系统固有特性
    

---

## Parameter Group一致性的确认逻辑

在instance变更的讨论中，基盘侧提出：

> 需确认parameter group一致性

其原因在于：

在RDS中：

`数据库的内存构成 并发控制参数 执行行为`

均由parameter group控制。

若出现以下情况：

- regression与本番parameter group不同
    
- 或instance变更后自动调整参数
    

则可能导致：

- 内存分配比例变化
    
- 并发处理能力变化
    
- SQL执行行为变化
    

因此在instance变更前，需要确认：

- 本番与regression使用相同parameter group
    
- 或至少关键参数一致
    

若parameter group无差异，则：

> 不存在由安全设置或参数差异导致的技术风险。

---

## 单体性能测试在本次决策中的定位

通过本次讨论，明确了单体性能测试在instance变更判断中的工程定位。

### 单体测试可确认的内容

- SQL执行时间变化
    
- 执行计划变化
    
- 内存结构变化
    
- 参数异常
    

即：

> 结构性性能劣化

---

### 单体测试无法保证的内容

- 高并发锁竞争（TM/TX lock）
    
- CPU饱和
    
- I/O队列堆积
    
- 跨AZ通信放大效应
    

这些属于：

> 负荷型性能问题

需要综合测试或本番运行后才能完全确认。

---

## 关于OS升级与instance变更的关系

项目中还存在后续：

`Oracle OS版本升级`

若instance变更与OS升级同时实施，则：

- 性能问题难以归因
    
- 风险叠加
    

因此建议的工程顺序为：

`① instance变更（4月） ② 本番稳定确认 ③ OS升级（3月计划中的变更） ④ 再次性能确认`

在regression中提前进行：

`R6i + 新OS`

的组合验证，仅能确认：

- 无致命兼容性问题
    

但无法100%保证本番在真实负荷下无问题。

---

## 最终工程判断逻辑

综合本阶段的技术讨论，instance变更的判断逻辑整理如下：

### 单体测试的定位

单体性能测试的作用为：

> 否决测试（排除结构性风险）

而不是：

> 保证测试（保证本番无问题）

---

### instance变更的可行性判断条件

若在R6i单体测试中：

- 无明显性能劣化
    
- 无执行计划异常
    
- 无内存结构异常
    
- 系统可正常运行
    

则可判断：

> 不存在结构性风险  
> 可作为4月实施instance变更的判断依据

但仍需认识到：

- 高并发锁竞争等问题
    
- 仅能在综合测试或本番负荷中确认
    

---

## 本阶段的关键经验总结

通过本次instance变更讨论，可以总结出以下工程经验。

### 经验一：性能不是硬件指标的线性函数

CPU性能提升，并不必然带来系统整体性能提升。

在高并发系统中：

`CPU更快 → 并发推进更快 → 锁竞争更集中 → 系统反而变慢`

---

### 经验二：测试是分层的

不存在一次测试可以覆盖全部风险。

|测试类型|作用|
|---|---|
|单体测试|排除结构性问题|
|综合测试|发现并发瓶颈|
|本番运行|验证真实环境风险|

---

### 经验三：实例变更属于系统级风险控制问题

本次工作的本质不是：

- 开发新功能
    
- 修复单一Bug
    

而是：

> 在系统结构不变的前提下，控制基础设施变更风险。

# 以上为讨论的内容，实际情况如下
下面是把你刚才那段内容整理成**可以直接放进项目资料中的正式版本**。  
我保持和你前文一致的结构与语气，避免口语化表达，方便你直接拼接到现有文档里。

---

# 单体性能测试用例选择方针（R6i事前验证）

在决定以单体性能测试作为4月是否实施R6i instance变更的判断依据后，需要对**测试用例的选择标准**进行统一整理。

本次单体测试的目的，并非进行完整的性能验证，而是：

> 在最小验证范围内，确认R6i实例不存在结构性性能问题。

因此，在测试用例选择上，需要兼顾：

- 既有性能改修效果的确认
    
- 不同SQL负荷特性的覆盖
    
- 实际业务场景的代表性
    

基于上述目标，向BP侧提出如下测试用例选择观点。

---

## 一、基于既有性能改修结果的选择观点

在此前使用 `m5.xlarge` 环境进行单体测试时：

- 存在无性能问题的case
    
- 亦存在性能不达标、已实施改修的case
    

因此，为了确认：

- 既有改修在R6i下是否仍然有效
    
- R6i是否对不同类型case产生不同影响
    

本次测试用例按以下两类进行选择。

### ① m5环境下无性能问题的case

目的：

- 确认在原本无问题的业务中
    
- R6i不会引入新的性能劣化
    

即：

> 验证R6i在正常业务场景下的基本性能稳定性。

---

### ② m5环境下存在性能问题并已实施改修的case

目的：

- 确认既有改修在R6i环境下仍然有效
    
- 判断R6i是否改变原有性能特性
    

即：

> 验证改修效果在新instance上的一致性。

---

## 二、基于SQL负荷特性的技术观点

除历史测试结果外，还需从技术角度覆盖不同负荷类型的SQL与业务场景。

本次用例选择参考以下典型负荷模式。

---

### ① CPU负荷型SQL

特征：

- 复杂计算
    
- 大量逻辑处理
    
- CPU使用率较高
    

目的：

- 确认新CPU架构下的执行性能
    
- 判断是否存在执行特性变化
    

---

### ② IO复合型SQL

特征：

- 数据读取量大
    
- buffer cache命中率敏感
    
- 对存储性能依赖较高
    

目的：

- 确认R6i下IO行为是否稳定
    
- 判断是否存在读写性能变化
    

---

### ③ 短时间内大量SQL访问型业务

特征：

- 单次业务中SQL往返次数多
    
- 对网络延迟与并发节奏敏感
    

目的：

- 确认instance变更后
    
- 业务整体处理时间无明显劣化
    

---

### ④ 执行计划确认范围的限制

考虑到：

- 执行计划逐条确认成本较高
    
- 部分关键SQL已存在hint固定执行路径
    

因此本次单体测试中：

- 不对所有SQL执行计划逐一确认
    
- 仅在出现明显性能异常时进行个别确认
    

---

### ⑤ 实际JP1 Job的代表性业务

除在线业务外，还需纳入：

- 实际JP1批处理job
    

目的：

- 覆盖夜间批处理负荷
    
- 确认批处理性能无明显劣化
    

---

## 三、本番与regression环境差异的确认

在单体测试方案确定后，需要确认：

> 是否存在仅在本番环境中存在、而regression无法观测到的特殊设定。

针对该问题，与基盘侧进行了确认。

---

### 基盘侧确认结果

基盘侧主要提出以下观点：

#### ① Parameter Group一致性确认

- instance变更时，可能影响parameter group
    
- 基盘侧会确认：
    
    - 本番与regression使用相同parameter group
        
    - 内存分配等核心参数一致
        

目的：

> 确保数据库资源模型在两环境中一致。

---

#### ② AZ构成一致性

基盘侧说明：

- 本番与regression的AZ构成一致
    
- 不存在环境结构上的差异
    

因此可以推导：

> 若regression中出现AZ相关性能问题  
> 则本番在相同条件下亦可能出现。

即：

- regression观测到的AZ差异问题
    
- 并非测试环境特有现象
    
- 属于系统架构固有特性
    

---

### 关于安全设置差异的情况

在本阶段讨论中：

- 基盘侧未特别提出安全设置（Security Group、IAM等）差异风险
    
- 且regression环境中已成功进行：
    
    - 应用 + R6i实例 的打键验证
        

说明：

- 基本网络路径与访问权限正常
    
- 不存在“无法连接DB”的重大安全配置问题
    

因此判断：

> 不存在仅在本番环境中才会出现的安全访问风险。

---

## 四、本阶段单体测试的工程定位

基于以上讨论，明确本次单体测试的工程定位如下：

### 单体测试的目的

`排除结构性性能风险`

而不是：

`保证本番在高负荷下完全无问题`

---

### 单体测试可确认的内容

- SQL执行时间变化
    
- 执行计划异常
    
- 内存结构变化
    
- 参数异常
    

---

### 单体测试无法保证的内容

- 高并发锁竞争（TM/TX lock）
    
- CPU饱和
    
- I/O队列堆积
    
- 跨AZ通信放大效应
    

---

## 五、单体测试结果的使用方式

若在R6i单体测试中确认：

- 无明显性能劣化
    
- 系统可稳定运行
    
- 无结构性异常
    

则可作为：

> 4月实施R6i instance变更的判断依据。

但需在本番适用后：

- 重点监控性能指标
    
- 必要时准备回退方案

# 关于目前方针的评价
1）对你现在这个方针的工程评价  
2）security部分到底在担心什么、影响大不大  
3）你和基盘确认前需要具备的最低限度知识与确认清单

全部按**真实项目工程逻辑**来讲，不说理论空话。

---

# 一、对你现在单体测试方针的评价

先给结论：

> 你现在这个测试方针，在“4月前必须决策是否更换instance”的前提下，是一个**合理且现实的工程折中方案**。

从工程角度看，这个方案有三个优点。

---

## 优点①：覆盖了“结构性风险”

你选case的两个维度：

### 维度1：历史性能表现

- m5下正常的case
    
- m5下有问题并改修的case
    

这个设计非常合理，因为它能回答两个关键问题：

|目的|对应case|
|---|---|
|R6i会不会把正常业务变慢|原本正常的case|
|改修效果在R6i下是否成立|改修过的case|

这就是典型的：

> “回归验证 + 稳定性确认”结构

这是工程上常见的验证思路。

---

### 维度2：SQL负荷类型

你选的：

- CPU负荷型
    
- IO复合型
    
- 短时间大量SQL业务
    
- JP1 job
    

这相当于在做：

> “负荷模型覆盖”

这一步的价值是：

即使case数量不多，也能：

`覆盖主要性能瓶颈类型`

这在资源受限的情况下是合理做法。

---

## 优点②：没有陷入“全量验证陷阱”

很多项目在这种阶段会犯的错误是：

`既然不确定 → 那就全部重测`

结果：

- 时间不够
    
- 钱不够
    
- 最后什么都做不了
    

你们现在的策略是：

`选关键case 做最小验证 作为决策依据`

这是典型的：

> 工程现实主义决策方式

在大型金融系统中很常见。

---

## 唯一需要注意的一点

你现在这个方针**只有一个隐含前提**：

> regression环境在结构上与本番没有关键差异。

否则：

`regression测OK 本番结构不同 → 结果失效`

而这正好就是你现在担心的：

`security设置是否有差异`

这个问题问得是对的。

---

# 二、security那部分到底在担心什么

先给你一句最真实的结论：

> 在“instance type变更”的场景下，security设置通常不是主要风险点，但必须做一次结构确认。

原因如下。

---

## 什么叫“security相关设置”

在RDS环境里，“security”通常包括这几类：

|类别|具体内容|影响类型|
|---|---|---|
|网络访问控制|Security Group|能不能连DB|
|子网与路由|Subnet / Route|网络路径|
|权限控制|IAM角色|运维与监控|
|加密设置|KMS key|IO路径与延迟|
|RDS功能设置|Option Group|SSL、审计等|

---

## security问题通常有两种表现

### 类型1：致命型（连不上DB）

例如：

- SG端口没开
    
- 子网错误
    
- 路由错误
    

表现：

`连接超时 ORA-12541`

但你们已经在regression：

`app + r6i 正常打键`

说明：

> 这种致命型安全问题基本不存在。

---

### 类型2：隐性型（能连上但性能不同）

例如：

|差异|可能影响|
|---|---|
|不同KMS key|写入延迟不同|
|不同SG路径|网络路径变化|
|不同子网|AZ或网络拓扑不同|

这种情况：

`能连DB 但性能行为不同`

这才是你现在真正要担心的。

---

# 三、你需不需要和基盘确认security差异

答案是：

> 建议确认，但不需要深入到很细的安全策略层面，只需要做“结构一致性确认”。

因为你现在的目标不是：

`做安全审计`

而是：

`确认regression结果对本番是否有效`

所以只要确认：

`两边结构一致`

就可以了。

---

# 四、你在和基盘确认前需要具备的最低限度认知

你只需要理解一个核心概念：

---

## 云环境中的性能由“三层结构”决定

`① instance规格（CPU/内存） ② DB参数结构（parameter group） ③ 网络与存储路径（AZ、subnet、SG等）`

你现在：

- ① 正在变更（r5→r6i）
    
- ② 基盘说会确认parameter group
    
- ③ 你担心是否有差异
    

这就是一个完整的结构确认逻辑。

---

# 五、你可以向基盘确认的最小问题清单

不需要问太多，只问这3条就够。

---

## 确认点①：网络构成是否一致

`本番とregressionで、 RDSのsubnet groupおよびAZ構成に差異はありませんか。`

目的：

- 确认网络路径一致
    
- 防止不同AZ结构
    
## 含义A：资源实际落在哪个AZ

在同一个Region里（例如东京）会有 AZ-a / AZ-c 等。

- RDS 的 primary 实例当前在哪个AZ
    
- 应用（EC2/ECS等）在哪个AZ
    

如果出现：

- App 在 AZ-a
    
- DB 在 AZ-c
    

就会变成**跨AZ通信**，你们已经实测过会让响应变慢。

所以这里的「AZ構成」核心是在问：

> 本番和 regression 的“App与DB的AZ组合关系”是否一致？

---

## 含义B：Multi-AZ / Failover 时的行为与落点

如果是 Multi-AZ：

- primary / standby 分布在哪些AZ
    
- failover 后 primary 会切到哪个AZ（可能变化）
    

你们讨论的“切换后需要手动调整回来”其实就是这个行为。

所以「AZ構成」也包含：

> failover 或变更后，DB可能跑到不同AZ，这个行为在两环境是否一致？
---

## 确认点②：security group是否一致

`RDSに紐づくSecurity Groupについて、 本番とregressionで通信経路に影響する差分はありませんか。`

目的：

- 确认访问路径一致
    

---

## 确认点③：加密与option设置

`KMS設定やOption Groupについて、 性能影響が出るような差分はありませんか。`

目的：

- 防止加密路径或功能差异
    
- KMS 是 RDS 存储加密用的密钥管理（加密/解密由AWS处理）
    
- 一般情况下**性能影响很小**，但你问它的意义在于：
    
    - 本番和 regression 如果加密方式/密钥/相关设置不同
        
    - 有可能造成 I/O 路径或行为差异（尤其在敏感系统里常被要求一致）
---

# 六、一句话总结你的当前状态

从工程角度看：

> 你的单体测试方针是合理的，现在只差一步：确认regression与本番在基础结构上无关键差异。

只要这一步确认完：

`单体测试结果 → 就可以作为4月instance变更的合理判断依据`

# 关于Mutil AZ
> 在Multi-AZ构成中，Primary所在的AZ**并不是永久固定的**。  
> 即使没有灾害，也可能因为维护、实例变更、硬件问题等原因发生AZ切换。

也就是说：

> AZ并不是“只在灾害时才变化”的。

下面把这个逻辑讲清楚。

---

# 一、Multi-AZ中Primary的AZ本来就不是固定的

在RDS的Multi-AZ结构中：

`Primary：AZ-a Standby：AZ-c`

这是**当前状态**，不是“永久状态”。

AWS的设计思想是：

> Primary和Standby是可以随时互换角色的。

只要发生以下情况之一，就可能触发切换。

---

# 二、即使没有灾害，也会发生AZ切换的常见原因

常见有4类。

---

## 原因①：AWS例行维护（最常见）

例如：

- 底层宿主机维护
    
- 存储系统维护
    
- 网络设备维护
    
- RDS引擎补丁
    

AWS可能会执行：

`计划性failover`

过程：

`原： Primary：AZ-a Standby：AZ-c  维护AZ-a ↓ 切换 ↓ Primary：AZ-c`

整个过程中：

- 系统不会宕机很久
    
- AWS会认为这是“正常维护”
    

但对你们这种：

`非跨AZ性能设计系统`

就会出现：

`性能突然下降`

---

## 原因②：实例变更或参数变更

例如：

- instance type变更
    
- parameter group变更
    
- OS升级
    
- 存储变更
    

这些操作在Multi-AZ下常常会触发：

`一次failover`

所以你们之前：

`r5 → r6i`

时出现AZ变化，是完全正常的。

---

## 原因③：底层硬件问题（但未到灾害级别）

例如：

- 宿主机异常
    
- 存储节点不稳定
    
- 网络质量下降
    

AWS可能会主动做：

`预防性failover`

此时：

- 不算灾害
    
- 也不会对外宣布
    
- 但AZ会变化
    

---

## 原因④：手动操作或自动调度

某些情况下：

- AWS内部资源调度
    
- 用户执行某些操作
    

也可能触发切换。

---

# 三、所以AZ会不会长期稳定？

答案是：

> 在Multi-AZ结构中，Primary所在AZ**不保证长期固定**。

现实中：

|情况|AZ稳定性|
|---|---|
|短期（几天～几周）|通常稳定|
|中期（几个月）|可能发生1～2次切换|
|长期（1年以上）|几乎一定会切换过|

这在RDS里是正常现象。

---

# 四、AWS设计思想 vs 你们系统设计思想的冲突

这里有一个很典型的架构冲突。

---

## AWS的设计思想

`系统应能在任意AZ运行 性能差异应很小`

也就是：

> 跨AZ运行应该是“性能可接受”的状态。

---

## 你们当前系统的实际情况

`同AZ：性能正常 跨AZ：性能明显下降`

说明：

> 系统对AZ位置非常敏感。

这种系统在金融行业很多，但在云架构里属于：

`对AZ依赖较强的系统`

---

# 五、这意味着什么（非常重要的工程结论）

你们现在的系统行为本质上是：

`Primary AZ变化 → 网络延迟变化 → 性能波动`

而且这个变化：

`即使没有灾害 也会周期性发生`

所以从工程角度看：

> 你们系统未来一定会多次遇到这种AZ变化导致的性能波动。

这不是异常，而是结构性现象。

---

# 六、实际项目中的常见运维策略

对于这种系统，常见有两种策略。

---

## 策略A：接受跨AZ性能下降（推荐的云原生方式）

做法：

- 优化SQL
    
- 减少往返
    
- 调整架构
    

目标：

`跨AZ也能接受`

这是AWS推荐的方向。

---

## 策略B：固定运行AZ（传统金融系统常见）

做法：

`发生failover ↓ 性能下降 ↓ 人工failback ↓ 切回原AZ`

也就是：

> 把灾备AZ当“临时应急机房”。

# 全体评价
本件の単体性能試験（R6i事前検証）の位置づけは、インスタンスタイプ変更に伴う構造的な性能劣化（パラメータ/メモリ構成/単体SQL性能の明確な悪化等）の有無を確認する「否決テスト」とする。
一方で、高並行時のロック競合やI/O飽和など負荷依存の性能問題は単体試験では保証できないため、総合性能試験または本番稼働後の監視にて評価する。

またAZ切替による性能差は、Multi-AZ運用に起因する構成上の特性であり、R5/R6iの差分というより運用・総合性能観点で扱うべき課題である。従ってインスタンス変更可否の判断は、同一AZ条件下での差分確認を主とする。

本番・regression間の比較前提を担保するため、Parameter Groupに加え、暗号化（KMS）、Option Group、およびネットワーク関連設定（Subnet Group/SG等）に差分がないかを基盤側で確認し、差分がある場合は性能評価への影響有無を整理する。